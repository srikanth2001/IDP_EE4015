\section{Introduction}
In the last decade, the amount of data generated has increased dramatically. Data from genetics, video data, virtual reality, and other fields is exploding at an unprecedented rate. This data avalanche has necessitated the development of more effective compression methods for data storage and management. Data storage, on the other hand, is no longer for archival purposes. In modern applications, the majority of the stored data must be retrieved and analysed on a regular basis in order to make statistical choices. This has prompted the development of a new class of data compressors: efficient compressors that allow for computation on the compressed data while remaining rate efficient. shows up when source sequences are very long. In other words, to query a single source symbol,traditional algorithms require accessing a number of stored bits that scale with the length of the sequence. So asymptotically, as the sequence length n tends to infinity, one needs to access a large number of stored bits (scaling with n) to query a single bit.We are interested in constructions that allow close-to-optimal compression with efficient random access. When the compression sizes are quite large, the ability to deal with the compressed data without first decompressing the dataset is especially important (say 100x). We've previously seen how they can help with a variety of issues. In the realm of genomics, for example, much effort has gone into developing compressors that efficiently compress the 2D-tabular variant-call dataset while also allowing for random decompression of any row or column.

We're looking for a way to save a source sequence with the fewest possible bits while yet permitting a query of any place in the sequence using only a few bits of the compressed sequence. To recover a single symbol using classic compressors like Lempel-Ziv based techniques, one must access the complete compressed sequence. This is desired since these algorithms' space efficiency becomes apparent when source sequences are quite long. To put it another way, standard algorithms involve accessing a number of stored bits that grow with the length of the sequence to query a single source symbol.As the sequence length n approaches infinity, accessing a large number of stored bits (scaling with n) is required to query a single bit.We're looking for data structures that allow for near-optimal compression while maintaining efficient random access.